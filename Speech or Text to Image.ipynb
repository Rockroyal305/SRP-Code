{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "208698dd",
   "metadata": {
    "id": "rf5pf_mwOqCm"
   },
   "source": [
    "### Install package/Get into correct directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd19e6eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aL8du-leNk7F",
    "outputId": "1f9ea07a-8e00-442d-8dc4-8c56e5ac633d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rockr\\Desktop\\Code\\SRP\\SRP-Code\\glide-text2im\n"
     ]
    }
   ],
   "source": [
    "# %cd \"C:\\Users\\rockr\\Desktop\\Code\\SRP\\SRP Code\"\n",
    "# !git clone https://github.com/openai/glide-text2im.git\n",
    "# %pip install -q -e .\n",
    "%cd \"C:\\Users\\rockr\\Desktop\\Code\\SRP\\SRP-Code\\glide-text2im\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082ae5f4",
   "metadata": {
    "id": "MDMaMUwRO0Pm"
   },
   "source": [
    "### Set-up functions, models and options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4e3c7c5",
   "metadata": {
    "id": "BCSZT7R2NOGv"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import torch as th\n",
    "\n",
    "from glide_text2im.download import load_checkpoint\n",
    "from glide_text2im.model_creation import (\n",
    "    create_model_and_diffusion,\n",
    "    model_and_diffusion_defaults,\n",
    "    model_and_diffusion_defaults_upsampler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79d149f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set up sentence split function\n",
    "import re\n",
    "alphabets = \"([A-Za-z])\"\n",
    "prefixes = \"(Mr|St|Mrs|Ms|Dr)[.]\"\n",
    "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
    "starters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
    "websites = \"[.](com|net|org|io|gov)\"\n",
    "\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    text = \" \" + text + \"  \"\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = re.sub(prefixes, \"\\\\1<prd>\", text)\n",
    "    text = re.sub(websites, \"<prd>\\\\1\", text)\n",
    "    if \"Ph.D\" in text:\n",
    "        text = text.replace(\"Ph.D.\", \"Ph<prd>D<prd>\")\n",
    "    text = re.sub(\"\\s\" + alphabets + \"[.] \", \" \\\\1<prd> \", text)\n",
    "    text = re.sub(acronyms+\" \"+starters, \"\\\\1<stop> \\\\2\", text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" +\n",
    "                  alphabets + \"[.]\", \"\\\\1<prd>\\\\2<prd>\\\\3<prd>\", text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets +\n",
    "                  \"[.]\", \"\\\\1<prd>\\\\2<prd>\", text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.] \"+starters, \" \\\\1<stop> \\\\2\", text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.]\", \" \\\\1<prd>\", text)\n",
    "    text = re.sub(\" \" + alphabets + \"[.]\", \" \\\\1<prd>\", text)\n",
    "    if \"”\" in text:\n",
    "        text = text.replace(\".”\", \"”.\")\n",
    "    if \"\\\"\" in text:\n",
    "        text = text.replace(\".\\\"\", \"\\\".\")\n",
    "    if \"!\" in text:\n",
    "        text = text.replace(\"!\\\"\", \"\\\"!\")\n",
    "    if \"?\" in text:\n",
    "        text = text.replace(\"?\\\"\", \"\\\"?\")\n",
    "    text = text.replace(\".\", \".<stop>\")\n",
    "    text = text.replace(\"?\", \"?<stop>\")\n",
    "    text = text.replace(\"!\", \"!<stop>\")\n",
    "    text = text.replace(\"<prd>\", \".\")\n",
    "    sentences = text.split(\"<stop>\")\n",
    "    sentences = sentences[:-1]\n",
    "    sentences = [s.strip() for s in sentences]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09d1a773",
   "metadata": {
    "id": "a4QBvuzfNOG6"
   },
   "outputs": [],
   "source": [
    "### Pick which device to use for rendering\n",
    "\n",
    "has_cuda = th.cuda.is_available()\n",
    "device = th.device('cpu' if not has_cuda else 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf2d6929",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "cfd0b7ad7ed24c2491e40a27b173c230",
      "6b84156c40384924a8d86d94213fbaff",
      "d2b173c7aad347fb8f5791b924f2d9b8",
      "d696f75f5be442cbba6c5dd6c31b5716",
      "5f989818f91d4e8f96fa2c182b50bb1c",
      "af5af961fe4f4e648784568b89db26e9",
      "b7a4807cd0434bb1b96cf40d485cef69",
      "ccab696cd7994d0fa19f8280370b3d32",
      "c2af0d5d956c421daff2fe86caae732e",
      "7fbc8a0b59944e50bb856424567661fe",
      "48acf713163d40bb9b30ec31e6884103"
     ]
    },
    "id": "7Zt1vrctNOG8",
    "outputId": "88282295-cb04-4c23-87cd-0cf616ec01e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total base parameters 385030726\n"
     ]
    }
   ],
   "source": [
    "### Create base model\n",
    "options = model_and_diffusion_defaults()\n",
    "options['use_fp16'] = has_cuda\n",
    "options['timestep_respacing'] = '100' # use 100 diffusion steps for fast sampling\n",
    "model, diffusion = create_model_and_diffusion(**options)\n",
    "model.eval()\n",
    "if has_cuda:\n",
    "    model.convert_to_fp16()\n",
    "model.to(device)\n",
    "model.load_state_dict(load_checkpoint('base', device))\n",
    "print('total base parameters', sum(x.numel() for x in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d60d9c9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "80da2ea2cf814a939b80491f46f1d356",
      "be987294bb86474a8af1be3ca12332e9",
      "74c6566610fa46ad8aade31cfbfde4a8",
      "af07f1c250d2472580af9bde5eebc2d6",
      "e78bbb1eba044a0f9f6b39a0bda40b5c",
      "1436b818057a491bb0dcae1747f5cc89",
      "02f87658f111452a8fe00046fbefd49f",
      "92edd58b3848462cb8a7f81207adcfc2",
      "aed38e49c1df44edbcfde4cbdb314bc5",
      "075d3fb5f96d40b982196554d093f673",
      "534d69c3b6364f48bb2f692f4dc98894"
     ]
    },
    "id": "JoJ_xoYdNOG-",
    "outputId": "38798c34-2b00-4873-c1e0-a63966549fb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total upsampler parameters 398361286\n"
     ]
    }
   ],
   "source": [
    "### Create upsampler model\n",
    "options_up = model_and_diffusion_defaults_upsampler()\n",
    "options_up['use_fp16'] = has_cuda\n",
    "options_up['timestep_respacing'] = 'fast27' # use 27 diffusion steps for very fast sampling\n",
    "model_up, diffusion_up = create_model_and_diffusion(**options_up)\n",
    "model_up.eval()\n",
    "if has_cuda:\n",
    "    model_up.convert_to_fp16()\n",
    "model_up.to(device)\n",
    "model_up.load_state_dict(load_checkpoint('upsample', device))\n",
    "print('total upsampler parameters', sum(x.numel() for x in model_up.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1451ec47",
   "metadata": {
    "id": "U55PSe1zNOHA"
   },
   "outputs": [],
   "source": [
    "def show_images(batch: th.Tensor):\n",
    "    \"\"\" Display a batch of images inline. \"\"\"\n",
    "    scaled = ((batch + 1)*127.5).round().clamp(0,255).to(th.uint8).cpu()\n",
    "    reshaped = scaled.permute(2, 0, 3, 1).reshape([batch.shape[2], -1, 3])\n",
    "    display(Image.fromarray(reshaped.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ffe2f2",
   "metadata": {},
   "source": [
    "### Determine if user wants audio or text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e3427c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.io.wavfile import read as read_wav\n",
    "from google.cloud import storage, speech\n",
    "\n",
    "type = input(\"Would you like to use Text (T) or Speech (S) input?\")\n",
    "if(type == \"T\" or type == \"t\"):\n",
    "    text = input(\"Please input the text:\")\n",
    "    sentences = split_into_sentences(text)\n",
    "else:\n",
    "    found_file = False\n",
    "    file_path = input(\n",
    "        \"Enter the path to an audio file. Take note that speech to text works best if each sentence is clearly separated. Also be aware that this program cannot generate images of people. You must input a .wav file:\")\n",
    "    while(found_file == False):\n",
    "        found_file = os.path.exists(file_path) and file_path[-3:] == \"wav\"\n",
    "        if(found_file == False):\n",
    "            file_path = input(\"That file-path was invalid, Please try again:\")\n",
    "    print(\"File was succesfully input!\")\n",
    "    sampling_rate, data = read_wav(file_path)\n",
    "    print(\"The sampling rate of the file is: {} Hz.\".format(sampling_rate))\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = r\"C:\\Users\\rockr\\Desktop\\Code\\SRP\\sample-key.json\"\n",
    "    def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "        {\n",
    "            # Uploads a file to the bucket.\n",
    "\n",
    "            # The ID of your GCS bucket\n",
    "            # bucket_name = \"your-bucket-name\"\n",
    "\n",
    "            # The path to your file to upload\n",
    "            # source_file_name = \"local/path/to/file\"\n",
    "            \n",
    "            # The ID of your GCS object\n",
    "            # destination_blob_name = \"storage-object-name\"\n",
    "        }\n",
    "        storage_client = storage.Client()\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "        blob.upload_from_filename(source_file_name)\n",
    "        {\n",
    "            # print(\n",
    "            #     \"File {} uploaded to {}.\".format(\n",
    "            #         source_file_name, destination_blob_name\n",
    "            #     )\n",
    "            # )\n",
    "        }\n",
    "        print(\"File was successfully uploaded to Google Cloud Storage!\")\n",
    "    upload_blob(\"srp_speech_to_text\", file_path, \"audio_file_for_transcription.wav\")\n",
    "\n",
    "    # Instantiates a client\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    # The name of the audio file to transcribe\n",
    "    gcs_uri = \"gs://srp_speech_to_text/audio_file_for_transcription.wav\"\n",
    "\n",
    "    audio = speech.RecognitionAudio(uri=gcs_uri)\n",
    "\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=sampling_rate,\n",
    "        language_code=\"en-US\",\n",
    "    )\n",
    "\n",
    "    # Detects speech in the audio file\n",
    "    response = client.recognize(config=config, audio=audio)\n",
    "\n",
    "    sentences = []\n",
    "    for result in response.results:\n",
    "        s = (format(result.alternatives[0].transcript))\n",
    "        if(s[0] == ' '):\n",
    "            s = s[:0] + s[1:]\n",
    "        print(u\"Transcript: {}\".format(s))\n",
    "        print(\"Confidence: {}%\".format(int(100*result.alternatives[0].confidence)))\n",
    "        correct = input(\"Is this transcription correct? (Y/N)\")\n",
    "        if correct != \"Y\":\n",
    "            s = input(\"Please enter the correct sentence:\")\n",
    "        sentences.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b73e4489",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "9a3f80789d334cd5ae05d11ba96adc18",
      "c789e2ac565c413a9e09a7413a6d6367",
      "a5b5faaeade049fe85280c40a2324e78",
      "d5e791b252b54a40bd852cd803e0cb1b",
      "21f032f6aa894d31a939e690f3c76fee",
      "f65f6d6897ce4e0f80ea559a79ee417b",
      "988029f4449a4574846d699487319310",
      "5eab0b51ea9f41f09a37da03532e4609",
      "67f8cb19a0294a3bb4cc43950a214a49",
      "93503751ab044d88a396e740fe4fc568",
      "80b58fa377fb4af7b04233090a6491ff"
     ]
    },
    "id": "0vL5aXMgNOHF",
    "outputId": "330fb823-9619-458d-a4a7-73a9eaa00b6b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:09<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9912/1886405377.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;31m# Sample from the base model.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdel_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         samples = diffusion.p_sample_loop(\n\u001b[0m\u001b[0;32m     56\u001b[0m             \u001b[0mmodel_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0mfull_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"image_size\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"image_size\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Code\\SRP\\SRP-Code\\glide-text2im\\glide_text2im\\gaussian_diffusion.py\u001b[0m in \u001b[0;36mp_sample_loop\u001b[1;34m(self, model, shape, noise, clip_denoised, denoised_fn, cond_fn, model_kwargs, device, progress)\u001b[0m\n\u001b[0;32m    387\u001b[0m         \"\"\"\n\u001b[0;32m    388\u001b[0m         \u001b[0mfinal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m         for sample in self.p_sample_loop_progressive(\n\u001b[0m\u001b[0;32m    390\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m             \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Code\\SRP\\SRP-Code\\glide-text2im\\glide_text2im\\gaussian_diffusion.py\u001b[0m in \u001b[0;36mp_sample_loop_progressive\u001b[1;34m(self, model, shape, noise, clip_denoised, denoised_fn, cond_fn, model_kwargs, device, progress)\u001b[0m\n\u001b[0;32m    439\u001b[0m             \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m                 out = self.p_sample(\n\u001b[0m\u001b[0;32m    442\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m                     \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Code\\SRP\\SRP-Code\\glide-text2im\\glide_text2im\\gaussian_diffusion.py\u001b[0m in \u001b[0;36mp_sample\u001b[1;34m(self, model, x, t, clip_denoised, denoised_fn, cond_fn, model_kwargs)\u001b[0m\n\u001b[0;32m    338\u001b[0m                  \u001b[1;33m-\u001b[0m \u001b[1;34m'pred_xstart'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0mof\u001b[0m \u001b[0mx_0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \"\"\"\n\u001b[1;32m--> 340\u001b[1;33m         out = self.p_mean_variance(\n\u001b[0m\u001b[0;32m    341\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Code\\SRP\\SRP-Code\\glide-text2im\\glide_text2im\\respace.py\u001b[0m in \u001b[0;36mp_mean_variance\u001b[1;34m(self, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mp_mean_variance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp_mean_variance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrap_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcondition_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcond_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Code\\SRP\\SRP-Code\\glide-text2im\\glide_text2im\\gaussian_diffusion.py\u001b[0m in \u001b[0;36mp_mean_variance\u001b[1;34m(self, model, x, t, clip_denoised, denoised_fn, model_kwargs)\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m         \u001b[0mmodel_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m             \u001b[0mmodel_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Code\\SRP\\SRP-Code\\glide-text2im\\glide_text2im\\respace.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, ts, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[0mmap_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimestep_map\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[0mnew_ts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap_tensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_ts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9912/1886405377.py\u001b[0m in \u001b[0;36mmodel_fn\u001b[1;34m(x_t, ts, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mhalf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_t\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mcombined\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhalf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhalf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[0mmodel_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m             \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_out\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_out\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0mcond_eps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muncond_eps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Code\\SRP\\SRP-Code\\glide-text2im\\glide_text2im\\text2im_model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, timesteps, tokens, mask)\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_blocks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxf_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Code\\SRP\\SRP-Code\\glide-text2im\\glide_text2im\\unet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, emb, encoder_out)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTimestepBlock\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAttentionBlock\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Code\\SRP\\SRP-Code\\glide-text2im\\glide_text2im\\unet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, emb)\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0memb_out\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mskip_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    440\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 442\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    443\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Low resolution samples (64x64)\n",
    "\n",
    "for sentence in sentences:\n",
    "    human = \"man\" in sentence or \"woman\" in sentence or \"person\" in sentence or \"people\" in sentence or \"human\" in sentence\n",
    "    if human == True:\n",
    "        print(\"Sorry, this program cannot create images of people\")\n",
    "    else:\n",
    "        prompt = sentence\n",
    "        # Sampling parameters\n",
    "        batch_size =  2\n",
    "        guidance_scale = 3.0\n",
    "\n",
    "        # Tune this parameter to control the sharpness of 256x256 images.\n",
    "        # A value of 1.0 is sharper, but sometimes results in grainy artifacts.\n",
    "        upsample_temp = 1.0\n",
    "\n",
    "        # Create the text tokens to feed to the model.\n",
    "        tokens = model.tokenizer.encode(prompt)\n",
    "        tokens, mask = model.tokenizer.padded_tokens_and_mask(\n",
    "            tokens, options['text_ctx']\n",
    "        )\n",
    "\n",
    "        # Create the classifier-free guidance tokens (empty)\n",
    "        full_batch_size = batch_size * 2\n",
    "        uncond_tokens, uncond_mask = model.tokenizer.padded_tokens_and_mask(\n",
    "            [], options['text_ctx']\n",
    "        )\n",
    "\n",
    "        # Pack the tokens together into model kwargs.\n",
    "        model_kwargs = dict(\n",
    "            tokens=th.tensor(\n",
    "                [tokens] * batch_size + [uncond_tokens] * batch_size, device=device\n",
    "            ),\n",
    "            mask=th.tensor(\n",
    "                [mask] * batch_size + [uncond_mask] * batch_size,\n",
    "                dtype=th.bool,\n",
    "                device=device,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # Create a classifier-free guidance sampling function\n",
    "        def model_fn(x_t, ts, **kwargs):\n",
    "            half = x_t[: len(x_t) // 2]\n",
    "            combined = th.cat([half, half], dim=0)\n",
    "            model_out = model(combined, ts, **kwargs)\n",
    "            eps, rest = model_out[:, :3], model_out[:, 3:]\n",
    "            cond_eps, uncond_eps = th.split(eps, len(eps) // 2, dim=0)\n",
    "            half_eps = uncond_eps + guidance_scale * (cond_eps - uncond_eps)\n",
    "            eps = th.cat([half_eps, half_eps], dim=0)\n",
    "            return th.cat([eps, rest], dim=1)\n",
    "\n",
    "        # Sample from the base model.\n",
    "        model.del_cache()\n",
    "        samples = diffusion.p_sample_loop(\n",
    "            model_fn,\n",
    "            (full_batch_size, 3, options[\"image_size\"], options[\"image_size\"]),\n",
    "            device=device,\n",
    "            clip_denoised= True,\n",
    "            progress= True,\n",
    "            model_kwargs=model_kwargs,\n",
    "            cond_fn= None,\n",
    "        )[:batch_size]\n",
    "        model.del_cache()\n",
    "\n",
    "        show_images(samples)\n",
    "\n",
    "        tokens = model_up.tokenizer.encode(prompt)\n",
    "        tokens, mask = model_up.tokenizer.padded_tokens_and_mask(\n",
    "            tokens, options_up['text_ctx']\n",
    "        )\n",
    "\n",
    "        # Create the model conditioning dict.\n",
    "        model_kwargs = dict(\n",
    "            # Low-res image to upsample.\n",
    "            low_res=((samples+1)*127.5).round()/127.5 - 1,\n",
    "\n",
    "            # Text tokens\n",
    "            tokens=th.tensor(\n",
    "                [tokens] * batch_size, device=device\n",
    "            ),\n",
    "            mask=th.tensor(\n",
    "                [mask] * batch_size,\n",
    "                dtype=th.bool,\n",
    "                device=device,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # Sample from the base model.\n",
    "        model_up.del_cache()\n",
    "        up_shape = (batch_size, 3, options_up[\"image_size\"], options_up[\"image_size\"])\n",
    "        up_samples = diffusion_up.ddim_sample_loop(\n",
    "            model_up,\n",
    "            up_shape,\n",
    "            noise=th.randn(up_shape, device=device) * upsample_temp,\n",
    "            device=device,\n",
    "            clip_denoised=True,\n",
    "            progress=True,\n",
    "            model_kwargs=model_kwargs,\n",
    "            cond_fn=None,\n",
    "        )[:batch_size]\n",
    "        model_up.del_cache()\n",
    "\n",
    "        show_images(up_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47457741",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305,
     "referenced_widgets": [
      "ece09b9a42a0472387be4e9683bc4ecc",
      "29bb4f23507c4c9281cacb8514ca4cb9",
      "f823f874a70f422797fca136ef1ae695",
      "92281fbca09e473a86e6ab5802179014",
      "48c59213f7464f0fb7b1864a23f429e1",
      "36d23e74b5364b0b8746419180754580",
      "02e7e75811444ac5a1d502f748cc10fe",
      "fec28112bbc14548ad643d76a2776244",
      "368c64cef7dc4fcca7f3a5728f1c371c",
      "a6082a6c130f4e43a21d89c624a72fcb",
      "e30d2b9feda74b0692ea8fbcfae30fc7"
     ]
    },
    "id": "FdFBhsSYNOHH",
    "outputId": "29c47104-261c-4afc-b659-d86477343ee2"
   },
   "outputs": [],
   "source": [
    "tokens = model_up.tokenizer.encode(prompt)\n",
    "tokens, mask = model_up.tokenizer.padded_tokens_and_mask(\n",
    "    tokens, options_up['text_ctx']\n",
    ")\n",
    "\n",
    "# Create the model conditioning dict.\n",
    "model_kwargs = dict(\n",
    "    # Low-res image to upsample.\n",
    "    low_res=((samples+1)*127.5).round()/127.5 - 1,\n",
    "\n",
    "    # Text tokens\n",
    "    tokens=th.tensor(\n",
    "        [tokens] * batch_size, device=device\n",
    "    ),\n",
    "    mask=th.tensor(\n",
    "        [mask] * batch_size,\n",
    "        dtype=th.bool,\n",
    "        device=device,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Sample from the base model.\n",
    "model_up.del_cache()\n",
    "up_shape = (batch_size, 3, options_up[\"image_size\"], options_up[\"image_size\"])\n",
    "up_samples = diffusion_up.ddim_sample_loop(\n",
    "    model_up,\n",
    "    up_shape,\n",
    "    noise = th.randn(up_shape, device=device) * upsample_temp,\n",
    "    device = device,\n",
    "    clip_denoised = True,\n",
    "    progress = True,\n",
    "    model_kwargs = model_kwargs,\n",
    "    cond_fn=None,\n",
    ")[:batch_size]\n",
    "model_up.del_cache()\n",
    "\n",
    "\n",
    "show_images(up_samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
